---
title: "Worflow"
author: "Workflow team"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document: 
    fig_height: 7
    fig_width: 7
    toc: yes
    code_folding: hide
    toc_float: yes
---

```{r options, echo=FALSE, results="hide",message=FALSE, error=FALSE, include=FALSE, autodep=TRUE}
knitr::opts_chunk$set(fig.align="center", cache=TRUE, error=FALSE, message=FALSE, warning=TRUE)
#bioconductor:
library(scRNAseq)
library(scone)
library(clusterExperiment)
library(BiocParallel)
#github
library(zinbwave)
library(slingshot)
#CRAN
library(doParallel)
library(ggplot2)
library(gplots)
library(magrittr)
library(matrixStats)
library(Rtsne)
library(RColorBrewer)
library(digest)
library(rARPACK)
set.seed(20)
if(packageVersion("clusterExperiment")<'1.3.0.9009') stop("must have current develop version to avoid bugs")
if(packageVersion("zinbwave")<'0.99.4.2') stop("must have current develop version to avoid bugs")
```

```{r}
runZinb <- TRUE
runClus <- TRUE
NCORES <- 7
```

FP: Version of zinbwave to use is last version of branch normvalues (branched from master). Parallel computing is now handle by BiocParallel. If you have a Windows machine, please update the code to allow paralell computing.

```{r parallel}
mysystem = Sys.info()[['sysname']]
switch(mysystem,
       Windows = {print("I'm a Windows PC and I'll use the snow for parallel computing (warning: it might be slower than serial computations).")},
       Linux = {print("I'm a penguin and I'll use package MulticoreParam for parallel computing.")},
       Darwin = {print("I'm a Mac and I'll use package doParallel for parallel computing.")})

if (mysystem == 'Darwin'){
  registerDoParallel(NCORES)
  register(DoparParam())
}else if (mysystem == 'Linux'){
  register(bpstart(MulticoreParam(workers=NCORES)))
}else{
  print('Please change this to allow parallel computing')
  register(SerialParam())
}
```

EAP: small request. Can everyone put a line between the beginning of a r chunk and text? It makes it nicely formated for my text editor. 

# Steps of the workflow

We propose a worklow to analyze single cell RNA-Seq with the following steps

- Dimensionality reduction using zinbwave to get W which should capture the biology,
- Cluster cells using clusterExperiment on W to get the cluster labels,   
- Get lineage using slingshot on W and cluster labels from clusterExperiment,  
- Get DE genes between lineages/clusters.  

Along the worflow, use deviance residuals as adjusted values.

```{r frog-picture, out.width='90%', fig.align='center', fig.cap = 'Worflow to analyze single cell RNASeq data'}
knitr::include_graphics('../vignettes/workflow.png')
```


## 1. Create a SummarizedExperiment object

Along the workflow, we want to use a unique SummarizedExperiement object carrying all the data we need.

EAP: I have updated the code to pull from a dataset on the repos that is created with the `createData.R` file. For now, I am filtering to the top 1000 most variable genes there, though we might want to add that to the code for the article. This will be slightly different data from Russell's, which didn't use all of the samples. We can adjust that decision later, or just compare the samples that are the same. (Russell's clusterLabels are in the meta data)

EAP: zinbFit doesn't accept data.frame objects, so currently have to have a `data.matrix` command. Should it be changed so that it does?

DR: I have changed the `createData.R` file so that it uses scone to filter out low-quality samples.

```{r datain}
if(!file.exists("../data/oe_se_1000Var.rda")) {
  source("createData.R")
}

load("../data/oe_se_1000Var.rda")
```

Here we only look at the 1000 most variable genes. EAP: see note above, I've commented out the filtering and added it to the `createData.R` for now. 

```{r batches}
batch <- colData(core)$Batch
```

Cells have been processed in `r length(unique(batch))` different batches

```{r batch}
col_batch = rep(brewer.pal(9, "Set1"), 2)
names(col_batch) = unique(batch)
table(batch)
```

We have qc measures from the data

```{r qc}
qc <- colData(core)[, !names(colData(core)) %in% c("Batch", "Experiment", "clusterLabels")]
head(qc, 2)
```

```{r clusterlabels}
clus.labels <- colData(core)[, "clusterLabels"]
```

In original work (FP: add ref), cells have been clustered into `r length(unique(clus.labels))` different clusters

```{r original}
col_clus <- c("transparent", brewer.pal(12, "Set3"), brewer.pal(8, "Set2"))
col_clus <- col_clus[1:length(unique(clus.labels))]
names(col_clus) <- sort(unique(clus.labels))
table(clus.labels)
```

Batches are kind of confounded with the biology

```{r clustbatch}
table(data.frame(batch = as.vector(batch),
                 cluster = clus.labels))
```

We have `r ncol(core)` cells.

```{r lookatdata}
dim(core)
assay(core)[1:3, 1:3]
```


## 2. Dimensionality reduction adjusting for gene and cell-level covariates

To cluster and get lineages we want to reduce the dimension of the data. We are going to use zinbwave to do so. First, let's fit zinbwave with first K = 0 to compute normalized values (i.e. deviance residuals) adjusted for batches. We could also adjust for gene length or GC content here. We then fit zinbwave to get the dimensionality reduced matrix W specifying the number of dimension K = 50. Eventually, we will call zinbwave just once where we would have an argument in zinbFit like "compute_normalized_values" in c(TRUE, FALSE). For K = 0 and K = 50, we correct for batch effect including batches in X.

```{r zinb}
fn <- '../data/zinb_batch.rda'
if (runZinb & !file.exists(fn)){
  print(system.time(se <- zinbDimRed(core, K = 50, X = '~ Batch',
                                       residuals = TRUE,
                                       normalizedValues = TRUE)))
  save(se, file = fn)
}else{
  load(fn)
}
```

DR: the chunk above and the similar one for clusterExperiment are fine for now, but in the published workflow, we should just rely on the markdown cache system (the code above doesn't check for changes to the file or code -- just that a version of the file exists).

### Normalized values

We use deviance residuals as normalized values for visualization. FP: explain rational: K=0 so residuals capture the bio adjusting for batch. Let's check that deviance residuals look ok.

FP: note to myself: why do we have infinite values in the residuals now? It shows the same results as before, but we should not see infinite values here!

```{r norm}
norm <- assays(se)$normalizedValues
if (sum(is.infinite(norm))>0){
  maxNorm = max(norm[!is.infinite(norm)])
  assays(se)$normalizedValues[is.infinite(norm)] <- maxNorm
  norm <- assays(se)$normalizedValues
}
norm[1:3,1:3]
```

Boxplot of the normalized values for each cell. It seems that correction for batches is ok.

```{r lookatnorm}
norm_order <- norm[, order(as.numeric(batch))]
col_order <- as.numeric(batch)[order(as.numeric(batch))]
boxplot(norm_order, main='Boxplot of normalized values\ncolor=batch',
        col = col_order, staplewex = 0, outline = 0, border = col_order,
        xaxt = 'n')
```

PCA on the normalized values where color are for batches on the left and previously found clusters on the right. We want no clustering on the left side and clustering on the right side.

```{r pcanorm}
pca <- prcomp(t(norm))
par(mfrow = c(1,2))
plot(pca$x, col = col_batch[batch], pch = 20,
     main="PCA of normalized values\ncolor=batch")
plot(pca$x, col = col_clus[as.character(clus.labels)], pch = 20,
     main = "PCA of normalized values\ncolor=cluster")
par(mfrow = c(1,1))
```

### Dimensionality reduction

Let's check that performing MDS on W we have something coherent with original clusters.

```{r lookatdimred}
W <- colData(se)[, grepl('^W', colnames(colData(se)))]
W <- as.matrix(W)
d <- dist(W)
fit <- cmdscale(d, eig = TRUE, k = 2)
plot(fit$points, col = col_clus[as.character(clus.labels)], main = 'MDS', pch = 20,
     xlab = 'Component 1', ylab = 'Component 2')
legend(x = 'bottomright', legend = unique(names(col_clus)), cex = .5,
       fill = unique(col_clus), title = 'Sample')
```


## 2. Clustering of the cells

We use clusterExperiment with W.

EP: I updated it to work on a SE object so that it has the meta data. If you have a summarized experiment object with W already, you could use that as long as assay(seObj) gives W. 


```{r rsec_50}
fn <- '../data/RSEC_W.rda'
if (runClus & !file.exists(fn)){
  #symbol for samples missing from original clustering
  seObj <- SummarizedExperiment(t(W), colData = colData(core))
  print(system.time(ceObj <- RSEC(seObj, k0s = 4:15, alphas = c(0.1),
                                  betas = 0.8, dimReduce="none",
                clusterFunction = "hierarchical01", minSizes=1,
                ncores = NCORES, isCount=FALSE,
                subsampleArgs = list(resamp.num=100,
                                     clusterFunction="kmeans",
                                     clusterArgs=list(nstart=10)),
                seqArgs = list(k.min=3, top.can=5), verbose=TRUE,
                combineProportion = 0.7,
                mergeMethod = "none", random.seed=424242)))
  save(ceObj, file = fn)
}else{
  load(fn)
}
```


```{r examineCombineMany}
plotClusters(ceObj, colPalette = c(bigPalette, rainbow(199)))
```

```{r plotcoclust}
plotCoClustering(ceObj)
```

```{r tableclust}
table(primaryClusterNamed(ceObj))
sum(primaryCluster(ceObj) == -1)
```

FP: Elizabeth, we are working with the W here, does the locfdr make sense in this context? I set eval=FALSE in the next chunk to skip the merging step, let me know if you would rather keep using it. And if we want to still use the merging step, would we want to include it in RSEC function arguments instead of separately?

EP: I don't think the merging step on the W makes a whole lot of sense -- the method is irrelevant. The merging is based on calculating the % of genes found significant (the specific method is arbitrary). The best thing would be to replace the W with residuals in the assay of `ceObj` (or whatever data that you will do the DE on for the time stuff below), and then run the merging step on that data.  I'm not particularly fond of `locfdr`. It was probably the method that gave the best merging to Russell and Diya. You'd really have to run `mergeClusters` setting `plotInfo="all"` and look at the results and decide both the cutoff level and the method. 

EP: Also, if you don't save the output of `mergeClusters` it doesn't update `ceObj`. I was calling it for just the resulting plots, since it was already merged in RSEC above. I've changed to code to update ceObj below. 

FP: Ha ok, good to know. I'll keep the eval=FALSE for the moment.

```{r examineMergeClusters,eval=FALSE}
#re-does merging simpling to make plot 
#something like:
#assay(ceObj)
# if that replacement data should be considered on the transformed scale in plots, etc, the transformation function should be fixed as well:
#transformation(ceObj)
ceObj<-mergeClusters(ceObj, mergeMethod = "locfdr",
              plotInfo = "mergeMethod", cutoff = 0.01)
```


So, let's look at a heatmap on normalized values.

FP: Elizabeth, I did not find how to define the column annotation track in the plot below to have the same colors as in ceObj@clusterLegend[[1]]. I tried to use arguments annColors and annCol from aheatmap as it is said in plotHeatmap documentation that for signature matrix arguments can be passed to aheatmap. But I got the error "The following arguments to aheatmap cannot be set by the user in plotHeatmap:Rowv,Colv,color,annCol,annColors".

EP: Fanny, you would need to use the argument 'clusterLegend'. That argument takes either the format of aheatmap (list with each element a *named* vector of colors) or the format of the clusterExperiment object (i.e. list with each element a matrix with columns for `name` and `color`). So I think the following code will run, though it might need the list to have names...

But an easier fix to the code would be to set `visualizeData` option. I haven't tested this because I don't have the objects need run, so let me know if there is error.

FP: it seems great to me, what do you think?

EP: We should be careful, because the default in plotHeatmap is to plot the 500 most variable genes (maybe a slightly paternalistic default). I've changed it to `all` in the code here. I've also added the plotting of the batch, experiment, and Russell's original clusters. We may not want to keep all of them, but probably at least Russell's clusters for comparison.

```{r heatmaps}
# sampleData <- data.frame(ours = primaryCluster(ceObj))
# plotHeatmap(assays(se)$normalizedValues,
#             main = 'Normalized values, 1000 most variable genes',
#             clusterSamplesData = ceObj@dendro_samples,
#             sampleData = as.matrix(sampleData),clusterLegend=ceObj@clusterLegend[1])
# easier fix:
colData(ceObj)$clusterLabels <- as.factor(colData(ceObj)$clusterLabels)
origClusterColors<-bigPalette[1:nlevels(colData(ceObj)$clusterLabels)]
experimentColors<-bigPalette[1:nlevels(colData(ceObj)$Experiment)]
batchColors<-bigPalette[1:nlevels(colData(ceObj)$Batch)]
metaColors<-list("Experiment"=experimentColors,"Batch"=batchColors,"clusterLabels"=origClusterColors)

plotHeatmap(ceObj, visualizeData = assays(se)$normalizedValues,
            whichClusters = "primary",clusterFeaturesData="all",
            clusterSamplesData = "dendrogramValue",
            sampleData=c("clusterLabels","Batch","Experiment"),
            clusterLegend=metaColors, annLegend=FALSE,
            main = 'Normalized values, 1000 most variable genes',
            breaks = 0.99)
```

```{r compareClusters}
plot(fit$points, col = col_clus[as.character(clus.labels)],
     main = 'MDS W, color = original clusters', pch = 20,
     xlab = 'Component1', ylab = 'Component2')
legend(x = 'bottomright', legend = unique(names(col_clus)), cex = .5,
       fill = unique(col_clus), title = 'Sample')
```

```{r compare}
palDF <- ceObj@clusterLegend[[1]]
pal <- palDF[, 'color']
names(pal) <- palDF[, 'name']
pal["-1"] = "transparent"
plot(fit$points, col = pal[primaryClusterNamed(ceObj)],
     main = 'MDS W, color = our new clusters', pch = 20,
     xlab = 'Component1', ylab = 'Component2')
legend(x = 'bottomright', legend = names(pal), cex = .5,
       fill = pal, title = 'Sample')
```


## 4. Pseudotime ordering

The goal of this section is to see if we need to refit zinbwave when we want to run slingshot. We first run slingshot on the W used by clusterExperiment. In the second part of this section, we fit zinbwave on the matrix of counts where the unassigned cells have been removed. For each part (without or with refitting zinbwave), we run slingshot in the supervised and unsupervised mode and try k=3, k=4, k=5 dimensions in W.

From what I understand, start original clusters are 1 and 5 (HBC) and end original clusters are 15 (Microvillus), 9 and 12 (neuron), and 4, 7 (Sus). Additionally, we want the GBC cluster to be a junction before the differentiation between Microvillus and Neuron. The correspondance with the original clusters is as follow

```{r tabagain}
table(data.frame(original = clus.labels, ours = primaryClusterNamed(ceObj)))
```

Cluster name | Description | Color | Correspondence
-------------|-------------|-------| ----------
c1 | HBC | blue | original 1, 5
c2 | GBC / immature neurons / MV 1 | green | original 2, 3, 11
c3 | Sus | red | original 4, 7
c4 | Neuron | orange | original 9, 12
c5 | Immature Neuron | purple | original 10, 14
c6 | new and small | brown | original 9
c7 | Microvillus | cyan | original 15

```{r kvec}
Kvec <- c(3, 4, 5)
```

### Use previous W

The input of slingshot is the W used for clusterExperiment where the number of dimensions is reduced to k where k in (3, 4, 5) here.

#### Unsupervised

K = 3 only one lineage: sus is right after HBC

K = 4 two lineages: sus is right after HBC, differ only in end point (neuron, new cluster)

K = 5 three lineages: hbc-gbc-immature neuron-new-neuron; hbc-gbc-mv; hbc-sus (perfect!)


```{r removeunassigned}
our_cl <- primaryClusterNamed(ceObj)
cl = our_cl[our_cl != "-1"]
pal = pal[names(pal) != '-1']
```

```{r slingshot_unsup}
for (k in Kvec){
  X <- W[our_cl != "-1", 1:k]

  lineages <- get_lineages(X, clus.labels = cl, start.clus = "c1")
  curves <- get_curves(X, clus.labels = cl, lineages = lineages)
  plot_curves(X, cl, curves, col.clus = pal)
  plot_tree(X, cl, lineages, col.clus = pal)

  print(paste0("K=", k))
  print(lineages$lineage1)
  print(lineages$lineage2)
  print(lineages$lineage3)
  print(lineages$lineage4)
  print(lineages$lineage5)
}
```

#### Supervised

K = 3 four lineages: might be good, three lineages are correct and the fourth is plausible.

K = 4 same as K=3

K = 5 same as K=3


```{r slingshot_sup}
for (k in Kvec){
  X <- W[our_cl != "-1", 1:k]

  lineages <- get_lineages(X, clus.labels = cl, start.clus = "c1",
                           end.clus = c("c3", "c6", "c7"))
  curves <- get_curves(X, clus.labels = cl, lineages = lineages)
  plot_curves(X, cl, curves, col.clus = pal)
  plot_tree(X, cl, lineages, col.clus = pal)

  print(paste0("K=", k))
  print(lineages$lineage1)
  print(lineages$lineage2)
  print(lineages$lineage3)
  print(lineages$lineage4)
  print(lineages$lineage5)
}
```


### Re-fitting zinbwave

#### Unsupervised

K = 3 four lineages: immature neurons as a end point (not good)

K = 4 same as K = 3

K = 5 same as K = 3

```{r refit_zinb}
fn <- '../data/refit_zinbwave_slingshot.rda'

if (runZinb & !file.exists(fn)){
  zinbList <- lapply(Kvec, function(k){
    zinbFit(se[, our_cl != "-1"], X = '~ Batch', K = k)
  })
  save(zinbList, file = fn)
}else{
  load(fn)
}
```

```{r slingshot_unsup_refit}
for(k in Kvec) {
  X <- getW(zinbList[[k - 2]])[, 1:k]

  lineages <- get_lineages(X, clus.labels = cl, start.clus = "c1")
  curves <- get_curves(X, clus.labels = cl, lineages = lineages)
  plot_curves(X, cl, curves, col.clus = pal)
  plot_tree(X, cl, lineages, col.clus = pal)

  print(paste0("K=", k))
  print(lineages$lineage1)
  print(lineages$lineage2)
  print(lineages$lineage3)
  print(lineages$lineage4)
  print(lineages$lineage5)
}
```

#### Supervised

K = 3 four lineages (the small new cluster is still an end point)

K = 4 same as K=3

K = 5 three lineages (correct)

```{r slingshot_sup_refit }
for(k in Kvec){
  X <- getW(zinbList[[k - 2]])[, 1:k]

  lineages <- get_lineages(X, clus.labels = cl, start.clus = "c1",
                           end.clus = c("c3", "c6", "c10"))
  curves <- get_curves(X, clus.labels = cl, lineages = lineages)
  plot_curves(X, cl, curves, col.clus = pal)
  plot_tree(X, cl, lineages, col.clus = pal)

  print(paste0("K=", k))
  print(lineages$lineage1)
  print(lineages$lineage2)
  print(lineages$lineage3)
  print(lineages$lineage4)
  print(lineages$lineage5)
}
```

CONCLUSION: K = 5 is never great as GBC is generally an end cluster. K = 4 is ok for all the methods and a bit better when zinbwave is refitted. K = 3 when refitting and supervized is good.  

It seems to me that using slingshot on W without re-fitting zinbwave with k = 4 gives good results where supervized mode is slightly better than unsupervized. It is just a one shot example and we should obviously not make a general conclusion, but I think that for the purpose of the workflow it is fine to use slingshot without refitting zinbwave. We should write a note to the user that it is better to refit zinbwave to have more power.

## 5. DE analysis

Here is the kind of plots we want to present

```{r de, eval = FALSE}
de <- read.csv('../data/oe_markers.txt', stringsAsFactors = F, header = F)
de <- de$V1
plotHeatmap(ceObj, 
            visualizeData = assays(se)$normalizedValues[rownames(se) %in% de, ],
            clusterSamplesData = "dendrogramValue",
            whichClusters = "primary",
            main = 'Normalized values, 1000 most variable genes',
            breaks = 0.99)
```

FP: Kelly, is it you who did the DE analysis for Russell paper? If yes, what tool did you use? On what data? The full quantile normalized counts? Do you have code available?

# Session Info

```{r}
sessionInfo()
```
